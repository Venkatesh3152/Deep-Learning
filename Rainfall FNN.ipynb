{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c27010c-f503-431d-8194-55354856cff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f2c0856-7671-4ba1-a1b5-da3546aaf77e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"C:/Users/COMP/anaconda3/deep learning/chennai_rainfall_2019_2023_mm (1) (1).csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5224bfee-5c55-4378-a7d0-ab65e7cf377e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Temperature (°C)</th>\n",
       "      <th>Humidity (%)</th>\n",
       "      <th>Wind Speed (km/h)</th>\n",
       "      <th>Rainfall (cm)</th>\n",
       "      <th>Rainfall (mm)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "      <td>31.0</td>\n",
       "      <td>74.5</td>\n",
       "      <td>13.3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-01-02</td>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "      <td>29.7</td>\n",
       "      <td>87.1</td>\n",
       "      <td>9.5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-01-03</td>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "      <td>31.3</td>\n",
       "      <td>79.5</td>\n",
       "      <td>12.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-01-04</td>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "      <td>33.0</td>\n",
       "      <td>80.1</td>\n",
       "      <td>13.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-01-05</td>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "      <td>29.5</td>\n",
       "      <td>83.5</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1821</th>\n",
       "      <td>2023-12-27</td>\n",
       "      <td>2023</td>\n",
       "      <td>12</td>\n",
       "      <td>30.2</td>\n",
       "      <td>81.1</td>\n",
       "      <td>10.5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1822</th>\n",
       "      <td>2023-12-28</td>\n",
       "      <td>2023</td>\n",
       "      <td>12</td>\n",
       "      <td>29.6</td>\n",
       "      <td>83.9</td>\n",
       "      <td>11.5</td>\n",
       "      <td>0.4</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1823</th>\n",
       "      <td>2023-12-29</td>\n",
       "      <td>2023</td>\n",
       "      <td>12</td>\n",
       "      <td>28.7</td>\n",
       "      <td>77.8</td>\n",
       "      <td>16.9</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1824</th>\n",
       "      <td>2023-12-30</td>\n",
       "      <td>2023</td>\n",
       "      <td>12</td>\n",
       "      <td>30.3</td>\n",
       "      <td>82.0</td>\n",
       "      <td>11.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1825</th>\n",
       "      <td>2023-12-31</td>\n",
       "      <td>2023</td>\n",
       "      <td>12</td>\n",
       "      <td>30.9</td>\n",
       "      <td>82.8</td>\n",
       "      <td>11.9</td>\n",
       "      <td>0.3</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1826 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date  Year  Month  Temperature (°C)  Humidity (%)  \\\n",
       "0     2019-01-01  2019      1              31.0          74.5   \n",
       "1     2019-01-02  2019      1              29.7          87.1   \n",
       "2     2019-01-03  2019      1              31.3          79.5   \n",
       "3     2019-01-04  2019      1              33.0          80.1   \n",
       "4     2019-01-05  2019      1              29.5          83.5   \n",
       "...          ...   ...    ...               ...           ...   \n",
       "1821  2023-12-27  2023     12              30.2          81.1   \n",
       "1822  2023-12-28  2023     12              29.6          83.9   \n",
       "1823  2023-12-29  2023     12              28.7          77.8   \n",
       "1824  2023-12-30  2023     12              30.3          82.0   \n",
       "1825  2023-12-31  2023     12              30.9          82.8   \n",
       "\n",
       "      Wind Speed (km/h)  Rainfall (cm)  Rainfall (mm)  \n",
       "0                  13.3            0.5            5.0  \n",
       "1                   9.5            0.1            1.0  \n",
       "2                  12.4            0.3            3.0  \n",
       "3                  13.1            0.1            1.0  \n",
       "4                  12.0            1.4           14.0  \n",
       "...                 ...            ...            ...  \n",
       "1821               10.5            0.1            1.0  \n",
       "1822               11.5            0.4            4.0  \n",
       "1823               16.9            0.1            1.0  \n",
       "1824               11.5            0.0            0.0  \n",
       "1825               11.9            0.3            3.0  \n",
       "\n",
       "[1826 rows x 8 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1f65722c-2ef1-41ce-9898-aff7778e2c17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Date', 'Year', 'Month', 'Temperature (°C)', 'Humidity (%)',\n",
       "       'Wind Speed (km/h)', 'Rainfall (cm)', 'Rainfall (mm)'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b5289fba-1afa-4f15-bbb8-ddd666fcd941",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select target column\n",
    "target = 'Rainfall (mm)'  # adjust if column name differs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e168366f-c325-4afc-85a4-0c4b27b9dbdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Convert series to supervised learning\n",
    "def create_dataset(series, window=5):\n",
    "    X, y = [], []\n",
    "    for i in range(len(series) - window):\n",
    "        X.append(series[i:i+window])\n",
    "        y.append(series[i+window])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "rainfall = data[target].values\n",
    "X, y = create_dataset(rainfall, window=7)  # use past 7 days\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e32bd532-0574-45ee-919c-42310fde2db1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (1455, 7) (1455,)\n",
      "Test shape: (364, 7) (364,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# Suppose X, y are already created\n",
    "# Normalize manually (like MinMaxScaler)\n",
    "X = X.astype(\"float32\")\n",
    "X = (X - X.min()) / (X.max() - X.min())\n",
    "\n",
    "# Train-test split manually (e.g., 80-20 split)\n",
    "split = int(0.8 * len(X))\n",
    "X_train, X_test = X[:split], X[split:]\n",
    "y_train, y_test = y[:split], y[split:]\n",
    "\n",
    "print(\"Train shape:\", X_train.shape, y_train.shape)\n",
    "print(\"Test shape:\", X_test.shape, y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b3a21db1-d76f-41f4-bc84-ea8b58f4f0ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    tf.keras.layers.Dense(32, activation='relu'),\n",
    "    tf.keras.layers.Dense(1)  # regression output\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "28ef82f8-37f6-4d2b-a801-e73de12e9110",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Adam' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[43mAdam\u001b[49m(learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m),\n\u001b[0;32m      2\u001b[0m               loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmse\u001b[39m\u001b[38;5;124m'\u001b[39m,  \u001b[38;5;66;03m# or 'mae'\u001b[39;00m\n\u001b[0;32m      3\u001b[0m               metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmae\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Adam' is not defined"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=Adam(learning_rate=0.001),\n",
    "              loss='mse',  # or 'mae'\n",
    "              metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "075605a5-b052-47fd-833c-fbd390bdd673",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "91/91 [==============================] - 1s 3ms/step - loss: 412.7646 - mae: 11.9760 - val_loss: 395.0941 - val_mae: 11.5461\n",
      "Epoch 2/70\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 252.6646 - mae: 10.0231 - val_loss: 233.2642 - val_mae: 10.9581\n",
      "Epoch 3/70\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 210.0849 - mae: 10.2877 - val_loss: 226.7944 - val_mae: 10.4483\n",
      "Epoch 4/70\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 204.6773 - mae: 9.8602 - val_loss: 222.9019 - val_mae: 10.1756\n",
      "Epoch 5/70\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 201.2193 - mae: 9.6489 - val_loss: 220.6019 - val_mae: 10.0359\n",
      "Epoch 6/70\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 198.9128 - mae: 9.3238 - val_loss: 219.4257 - val_mae: 9.8376\n",
      "Epoch 7/70\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 197.7052 - mae: 9.2174 - val_loss: 218.6476 - val_mae: 9.8112\n",
      "Epoch 8/70\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 196.7682 - mae: 9.0579 - val_loss: 218.1741 - val_mae: 9.7736\n",
      "Epoch 9/70\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 196.1597 - mae: 9.0150 - val_loss: 217.7121 - val_mae: 9.5039\n",
      "Epoch 10/70\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 195.3284 - mae: 8.9490 - val_loss: 217.2541 - val_mae: 9.4598\n",
      "Epoch 11/70\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 194.7432 - mae: 8.8649 - val_loss: 217.0664 - val_mae: 9.4502\n",
      "Epoch 12/70\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 194.1537 - mae: 8.7764 - val_loss: 216.8656 - val_mae: 9.3780\n",
      "Epoch 13/70\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 193.3612 - mae: 8.8168 - val_loss: 216.3037 - val_mae: 9.4649\n",
      "Epoch 14/70\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 192.6053 - mae: 8.7818 - val_loss: 216.2697 - val_mae: 9.3685\n",
      "Epoch 15/70\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 192.0287 - mae: 8.6902 - val_loss: 216.2003 - val_mae: 9.6444\n",
      "Epoch 16/70\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 191.6056 - mae: 8.7870 - val_loss: 215.5001 - val_mae: 9.4243\n",
      "Epoch 17/70\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 191.0394 - mae: 8.6840 - val_loss: 215.2558 - val_mae: 9.5227\n",
      "Epoch 18/70\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 190.3374 - mae: 8.7525 - val_loss: 214.9857 - val_mae: 9.4627\n",
      "Epoch 19/70\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 189.9921 - mae: 8.6920 - val_loss: 214.8557 - val_mae: 9.3925\n",
      "Epoch 20/70\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 189.1546 - mae: 8.7409 - val_loss: 214.6017 - val_mae: 9.3380\n",
      "Epoch 21/70\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 189.0225 - mae: 8.6692 - val_loss: 214.0122 - val_mae: 9.4942\n",
      "Epoch 22/70\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 188.7381 - mae: 8.7793 - val_loss: 213.9787 - val_mae: 9.4122\n",
      "Epoch 23/70\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 188.3214 - mae: 8.6475 - val_loss: 213.8619 - val_mae: 9.3523\n",
      "Epoch 24/70\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 187.7606 - mae: 8.7120 - val_loss: 213.7674 - val_mae: 9.2996\n",
      "Epoch 25/70\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 187.3398 - mae: 8.6367 - val_loss: 213.1308 - val_mae: 9.4968\n",
      "Epoch 26/70\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 186.4863 - mae: 8.7385 - val_loss: 215.0532 - val_mae: 9.2145\n",
      "Epoch 27/70\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 186.7751 - mae: 8.6513 - val_loss: 212.7592 - val_mae: 9.3229\n",
      "Epoch 28/70\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 186.2594 - mae: 8.6704 - val_loss: 212.9730 - val_mae: 9.2989\n",
      "Epoch 29/70\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 186.3575 - mae: 8.6736 - val_loss: 212.3245 - val_mae: 9.3919\n",
      "Epoch 30/70\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 185.7156 - mae: 8.6609 - val_loss: 212.6816 - val_mae: 9.3193\n",
      "Epoch 31/70\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 185.8727 - mae: 8.6533 - val_loss: 211.7610 - val_mae: 9.4731\n",
      "Epoch 32/70\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 185.3795 - mae: 8.6683 - val_loss: 211.6617 - val_mae: 9.4471\n",
      "Epoch 33/70\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 185.1845 - mae: 8.6851 - val_loss: 211.6034 - val_mae: 9.3984\n",
      "Epoch 34/70\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 184.4531 - mae: 8.6999 - val_loss: 214.2042 - val_mae: 9.2227\n",
      "Epoch 35/70\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 184.7866 - mae: 8.6361 - val_loss: 211.1511 - val_mae: 9.4542\n",
      "Epoch 36/70\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 184.3496 - mae: 8.6497 - val_loss: 211.2362 - val_mae: 9.4148\n",
      "Epoch 37/70\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 184.0126 - mae: 8.6168 - val_loss: 211.6328 - val_mae: 9.2961\n",
      "Epoch 38/70\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 184.3938 - mae: 8.6548 - val_loss: 210.8519 - val_mae: 9.4499\n",
      "Epoch 39/70\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 184.1991 - mae: 8.6540 - val_loss: 211.0468 - val_mae: 9.4840\n",
      "Epoch 40/70\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 183.4862 - mae: 8.6868 - val_loss: 211.8460 - val_mae: 9.3152\n",
      "Epoch 41/70\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 183.4727 - mae: 8.6268 - val_loss: 210.3556 - val_mae: 9.4088\n",
      "Epoch 42/70\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 183.6350 - mae: 8.6502 - val_loss: 210.2241 - val_mae: 9.3692\n",
      "Epoch 43/70\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 183.2630 - mae: 8.6259 - val_loss: 210.1050 - val_mae: 9.4708\n",
      "Epoch 44/70\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 183.2380 - mae: 8.6043 - val_loss: 209.9155 - val_mae: 9.4332\n",
      "Epoch 45/70\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 182.8825 - mae: 8.6873 - val_loss: 209.9056 - val_mae: 9.3200\n",
      "Epoch 46/70\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 182.8735 - mae: 8.6267 - val_loss: 210.0439 - val_mae: 9.3086\n",
      "Epoch 47/70\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 182.7574 - mae: 8.6296 - val_loss: 210.4664 - val_mae: 9.2380\n",
      "Epoch 48/70\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 182.5656 - mae: 8.6122 - val_loss: 209.1850 - val_mae: 9.4613\n",
      "Epoch 49/70\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 182.2816 - mae: 8.6304 - val_loss: 209.4031 - val_mae: 9.3537\n",
      "Epoch 50/70\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 182.4585 - mae: 8.6689 - val_loss: 210.2603 - val_mae: 9.3976\n",
      "Epoch 51/70\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 182.4503 - mae: 8.6130 - val_loss: 209.0182 - val_mae: 9.4904\n",
      "Epoch 52/70\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 182.0822 - mae: 8.6222 - val_loss: 208.5228 - val_mae: 9.3936\n",
      "Epoch 53/70\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 182.2754 - mae: 8.6692 - val_loss: 209.7293 - val_mae: 9.3160\n",
      "Epoch 54/70\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 181.8935 - mae: 8.6533 - val_loss: 209.6722 - val_mae: 9.2597\n",
      "Epoch 55/70\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 181.8757 - mae: 8.6580 - val_loss: 209.6288 - val_mae: 9.2476\n",
      "Epoch 56/70\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 181.6840 - mae: 8.5931 - val_loss: 208.4675 - val_mae: 9.3179\n",
      "Epoch 57/70\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 181.7237 - mae: 8.6082 - val_loss: 208.8774 - val_mae: 9.3187\n",
      "Epoch 58/70\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 181.6101 - mae: 8.5969 - val_loss: 208.1185 - val_mae: 9.4280\n",
      "Epoch 59/70\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 181.8671 - mae: 8.6424 - val_loss: 208.2932 - val_mae: 9.5126\n",
      "Epoch 60/70\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 181.9926 - mae: 8.6648 - val_loss: 208.7068 - val_mae: 9.2965\n",
      "Epoch 61/70\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 181.8237 - mae: 8.6041 - val_loss: 208.2164 - val_mae: 9.3290\n",
      "Epoch 62/70\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 181.4999 - mae: 8.6776 - val_loss: 208.0502 - val_mae: 9.5475\n",
      "Epoch 63/70\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 181.2668 - mae: 8.6288 - val_loss: 207.8949 - val_mae: 9.3108\n",
      "Epoch 64/70\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 181.4820 - mae: 8.6512 - val_loss: 208.3743 - val_mae: 9.2923\n",
      "Epoch 65/70\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 180.9461 - mae: 8.5852 - val_loss: 207.4913 - val_mae: 9.3508\n",
      "Epoch 66/70\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 181.2524 - mae: 8.6133 - val_loss: 208.2248 - val_mae: 9.5751\n",
      "Epoch 67/70\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 181.2186 - mae: 8.6174 - val_loss: 208.3081 - val_mae: 9.3374\n",
      "Epoch 68/70\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 181.1820 - mae: 8.6346 - val_loss: 209.3085 - val_mae: 9.2195\n",
      "Epoch 69/70\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 181.1725 - mae: 8.6065 - val_loss: 207.5139 - val_mae: 9.3999\n",
      "Epoch 70/70\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 181.0257 - mae: 8.5683 - val_loss: 207.3607 - val_mae: 9.3876\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2093b809240>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history=model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=100, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5f1225ea-d392-49af-a3d9-91e3b97e8c73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 951us/step - loss: 207.3607 - mae: 9.3876\n"
     ]
    }
   ],
   "source": [
    "loss, mae = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "62b1297c-0882-4521-b940-952d47fa1c0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 2ms/step\n",
      "Sample predictions: [4.103922   4.2483144  1.0624261  0.70500135 0.32853058]\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "print(\"Sample predictions:\", y_pred[:5].flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "97966f5e-998a-4dd9-968b-ee01af3eb0e4",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(\u001b[43mhistory\u001b[49m\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m], label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTrain Loss\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      4\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(history\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m], label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mValidation Loss\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      5\u001b[0m plt\u001b[38;5;241m.\u001b[39mxlabel(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'history' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "979fe0a4-8366-4a2f-bd8a-c8e0b53d40f7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (DL)",
   "language": "python",
   "name": "dl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
